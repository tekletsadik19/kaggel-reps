{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38c8c664",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-28T15:17:45.493829Z",
     "iopub.status.busy": "2023-04-28T15:17:45.492810Z",
     "iopub.status.idle": "2023-04-28T15:30:54.008537Z",
     "shell.execute_reply": "2023-04-28T15:30:54.006642Z"
    },
    "papermill": {
     "duration": 788.523875,
     "end_time": "2023-04-28T15:30:54.011361",
     "exception": false,
     "start_time": "2023-04-28T15:17:45.487486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 47009 images belonging to 2 classes.\n",
      "Found 11649 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 114s 1s/step - loss: 0.6892 - accuracy: 0.5412 - val_loss: 0.6062 - val_accuracy: 0.6819\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 111s 1s/step - loss: 0.5443 - accuracy: 0.7272 - val_loss: 0.4725 - val_accuracy: 0.7619\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 112s 1s/step - loss: 0.4072 - accuracy: 0.8244 - val_loss: 0.3091 - val_accuracy: 0.8800\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 114s 1s/step - loss: 0.3291 - accuracy: 0.8681 - val_loss: 0.2291 - val_accuracy: 0.9137\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 111s 1s/step - loss: 0.2741 - accuracy: 0.8906 - val_loss: 0.2140 - val_accuracy: 0.9175\n",
      "50/50 [==============================] - 13s 258ms/step - loss: 0.1986 - accuracy: 0.9244\n",
      "Test accuracy: 0.9243749976158142\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Collect and preprocess the data\n",
    "train_dir = \"../input/gender-classification-dataset/Training\"\n",
    "test_dir = \"../input/gender-classification-dataset/Validation\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(train_dir,\n",
    "                                               target_size=(150, 150),\n",
    "                                               batch_size=32,\n",
    "                                               class_mode='binary')\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(test_dir,\n",
    "                                             target_size=(150, 150),\n",
    "                                             batch_size=32,\n",
    "                                             class_mode='binary')\n",
    "\n",
    "# Step 2: Split the data into training and testing sets\n",
    "\n",
    "# No code is required here as the data has already been split using ImageDataGenerator.\n",
    "\n",
    "# Step 3: Extract features from the images\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Step 4: Train a classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_data,\n",
    "                    steps_per_epoch=100,\n",
    "                    epochs=5,\n",
    "                    validation_data=test_data,\n",
    "                    validation_steps=50)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_data, steps=50)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Step 6: Use the model to predict\n",
    "# Use the trained model to predict the gender of new facial images.\n",
    "# Provide an accuracy score for the model's predictions.\n",
    "\n",
    "# No code is required here as the accuracy has already been printed in Step 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a418d5e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T15:30:54.087948Z",
     "iopub.status.busy": "2023-04-28T15:30:54.086461Z",
     "iopub.status.idle": "2023-04-28T15:30:54.349519Z",
     "shell.execute_reply": "2023-04-28T15:30:54.347851Z"
    },
    "papermill": {
     "duration": 0.304782,
     "end_time": "2023-04-28T15:30:54.352567",
     "exception": false,
     "start_time": "2023-04-28T15:30:54.047785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 166ms/step\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# load the trained model\n",
    "\n",
    "# load the image to test\n",
    "test_image = image.load_img('/kaggle/input/mahlet/photo_2023-02-20_09-26-26.jpg', target_size=(150, 150))\n",
    "\n",
    "# convert the image to a numpy array\n",
    "test_image_array = image.img_to_array(test_image)\n",
    "\n",
    "# add an extra dimension to the array to match the input shape of the model\n",
    "test_image_array = np.expand_dims(test_image_array, axis=0)\n",
    "\n",
    "# make the prediction\n",
    "prediction = model.predict(test_image_array)\n",
    "\n",
    "# print the prediction (0 = male, 1 = female)\n",
    "print(prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 803.437138,
   "end_time": "2023-04-28T15:30:57.575393",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-28T15:17:34.138255",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
